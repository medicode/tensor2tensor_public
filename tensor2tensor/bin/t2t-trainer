#!/usr/bin/env python
# coding=utf-8
# Copyright 2017 The Tensor2Tensor Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

r"""Trainer for T2T models.

This binary perform training, evaluation, and inference using
the Estimator API with tf.learn Experiment objects.

To train your model, for example:
  t2t-trainer \
      --data_dir ~/data \
      --problems=algorithmic_identity_binary40 \
      --model=transformer
      --hparams_set=transformer_base
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import fathomt2t
import fathomairflow.dags.dag_management.xcom_manipulation as xcom
from fathomtf.services.model_management import upload_model_to_gcs

import os

# Dependency imports

from tensor2tensor.utils import registry
from tensor2tensor.utils import trainer_utils
from tensor2tensor.utils import usr_dir

import tensorflow as tf

flags = tf.flags
FLAGS = flags.FLAGS

# See trainer_utils.py for additional command-line flags.
flags.DEFINE_string("t2t_usr_dir", "",
                    "Path to a Python module that will be imported. The "
                    "__init__.py file should include the necessary imports. "
                    "The imported files should contain registrations, "
                    "e.g. @registry.register_model calls, that will then be "
                    "available to the t2t-trainer.")
flags.DEFINE_string("tmp_dir", "/tmp/t2t_datagen",
                    "Temporary storage directory.")
flags.DEFINE_bool("generate_data", False, "Generate data before training?")

flags.DEFINE_integer("eval_steps", 10, "Number of steps in evaluation.")
flags.DEFINE_string("output_dir", "", "Base output directory for run.")
flags.DEFINE_string("master", "", "Address of TensorFlow master.")
flags.DEFINE_string("schedule", "train_and_evaluate",
                    "Method of tf.contrib.learn.Experiment to run.")

##################
#
# FATHOM ADDITIONS
#
##################
flags.DEFINE_bool("debug_mode", False, "Truncate training for debug purposes")
flags.DEFINE_bool("profile", False, "Profile performance?")
# NOTE: this is set as REQUIRED, in main()
flags.DEFINE_string("airflow_pipeline_yaml", None,
    "For saving to assets.extra")
flags.DEFINE_string("description", "", 
    "Description for this run.  Used in model name.  E.g., 'special_softmax'.")

def main(_):
  tf.logging.set_verbosity(tf.logging.INFO)
  usr_dir.import_usr_dir(FLAGS.t2t_usr_dir)
  trainer_utils.log_registry()
  trainer_utils.validate_flags()
  output_dir = os.path.expanduser(FLAGS.output_dir)
  tmp_dir = os.path.expanduser(FLAGS.tmp_dir)
  if not FLAGS.data_dir:
    raise ValueError("You must specify a --data_dir")
  data_dir = os.path.expanduser(FLAGS.data_dir)
  tf.gfile.MakeDirs(output_dir)

  # Generate data if requested.
  if FLAGS.generate_data:
    tf.gfile.MakeDirs(data_dir)
    tf.gfile.MakeDirs(tmp_dir)
    for problem_name in FLAGS.problems.split("-"):
      tf.logging.info("Generating data for %s" % problem_name)
      problem = registry.problem(problem_name)
      problem.generate_data(data_dir, tmp_dir)

  if FLAGS.debug_mode:
    FLAGS.train_steps = 1
    FLAGS.eval_steps = 1

  # Run the trainer.

  def run_experiment():
    trainer_utils.run(
      data_dir=data_dir,
      model=FLAGS.model,
      output_dir=output_dir,
      train_steps=FLAGS.train_steps,
      eval_steps=FLAGS.eval_steps,
      schedule=FLAGS.schedule)
  
  if FLAGS.profile:
    with tf.contrib.tfprof.ProfileContext('/usr/data/output/tfprof',
                                          trace_steps=range(100),
                                          dump_steps=range(100)) as pctx:
      opts = tf.profiler.ProfileOptionBuilder.time_and_memory()
      pctx.add_auto_profiling('op', opts, range(100))

      run_experiment()

  else:
    run_experiment()

  if FLAGS.eval_early_stopping_steps is not None: 
    _pick_optimal_model()
  dir_path, model_name = upload_model_to_gcs(FLAGS=FLAGS)

  # NOTE: this must run LAST in the process, to make sure STDOUT is
  # appropriately populated.
  xcom.echo_yaml_for_xcom_ingest({'output_dir': dir_path,
                                  'gcs_subpath': model_name})


def _pick_optimal_model() -> None:
    """Update the checkpoint so that it points to the best model that was
    encountered during training. Here "best" is defined as the lowest or
    highest value of the chosen early stopping metric. (By default,
    lowest loss.)

    We do this automatically based on knowledge of how early stopping
    works; i.e., we take the model that prevented early stopping from
    stopping before it did.
    """

    if FLAGS.debug_mode:
        return

    checkpoint_state = tf.train.get_checkpoint_state(FLAGS.output_dir)
    all_checkpoint_paths = list(checkpoint_state.all_model_checkpoint_paths)

    def extract_step(path):
        """Extract the step number from a checkpoint path

        Args:
            path: a path, e.g., model.ckpt-17

        Returns:
            step: the step number as an int, e.g., 17
        """
        return int(path[path.rindex('-') + 1:])

    # get available step numbers
    steps = [(extract_step(path), path) for path in all_checkpoint_paths]
    steps = sorted(steps)
    steps, all_checkpoint_paths = zip(*steps)
    all_checkpoint_paths = list(all_checkpoint_paths)

    # the step we want is the last one that would have allowed us to
    # stop when we did (at steps[-1])
    thresh = steps[-1] - FLAGS.eval_early_stopping_steps

    # get the last step that is <= thresh. Note that the early
    # stopping flags are phrased in terms of step number, not how many
    # times we've run eval.
    best_step_index = [step <= thresh for step in steps].index(False) - 1
    assert best_step_index >= 0, 'Early stopping stopped before it should have'


    # this is the checkpoint we want
    checkpoint_path = all_checkpoint_paths[best_step_index]

    # hack FIXME TODO XXX
    # We are about to move the best model into an export folder
    dirname, basename = os.path.split(checkpoint_path)
    checkpoint_path = os.path.join(dirname, 'export', basename)

    print('Early stopping chose checkpoint', checkpoint_path)

    tf.train.update_checkpoint_state(
        FLAGS.output_dir,
        checkpoint_path,
        all_checkpoint_paths + [checkpoint_path])
      
    
if __name__ == "__main__":
  tf.flags.mark_flag_as_required('airflow_pipeline_yaml')
  tf.flags.mark_flag_as_required('gcs-subpath')
  tf.app.run(main)
